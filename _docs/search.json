[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "Chronicle collects and stores logs and metrics in a series of parquet files.\nUse read_chronicle() to read either logs or metrics, by specifying the path to the parquet set you need.\nThe file tree looks like this, with logs and metrics in separate folders inside v1.\n.\n└── v1/\n    ├── logs/\n    └── metrics/\nInside both logs and metrics the data is stored by date, separated by year, month and day.\n.\n└── v1/\n    ├── logs/\n    │   └── 2023/\n    │       ├── 02/\n    │       │   ├── 01\n    │       │   ├── 02\n    │       │   ├── 03\n    │       │   ├── 04\n    │       │   ├── 05\n    │       │   └── ...\n    │       ├── 03\n    │       ├── 04\n    │       └── ...\n    └── metrics/\n        └── 2023/\n            ├── 02/\n            │   ├── 01\n            │   ├── 02\n            │   ├── 03\n            │   ├── 04\n            │   ├── 05\n            │   └── ...\n            ├── 03\n            ├── 04\n            └── ...\n\nsource\n\n\n\n read_chronicle_logs (path:str, version:str='v1')\n\nRead a chronicle logs parquet file into a polars dataframe.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nPath to dataset,\n\n\nversion\nstr\nv1\ncurrently must be v1\n\n\nReturns\nDataFrame\n\n\n\n\n\n\nsource\n\n\n\n\n read_chronicle_metrics (path:str, version:str='v1')\n\nRead a chronicle metrics parquet file into a polars dataframe.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nPath to dataset,\n\n\nversion\nstr\nv1\ncurrently must be v1\n\n\nReturns\nDataFrame\n\n\n\n\n\n\nz = read_chronicle_metrics(\"./data\")\nassert type(z) == pl.dataframe.frame.DataFrame\nassert z.columns == [\n    'service',\n    'host',\n    'os',\n    'attributes',\n    'name',\n    'description',\n    'unit',\n    'type',\n    'timestamp',\n    'value_float',\n    'value_int',\n    'value_uint',\n    'value_column'\n]\n\n\nz = read_chronicle_logs(\"./data\")\nassert type(z) == pl.dataframe.frame.DataFrame\nassert z.columns == [\n    'service', \n    'host', \n    'os', \n    'attributes', \n    'body', \n    'timestamp'\n]"
  },
  {
    "objectID": "core.html#analyse-metrics",
    "href": "core.html#analyse-metrics",
    "title": "core",
    "section": "Analyse metrics",
    "text": "Analyse metrics\n\nsource\n\nChronicleMetrics\n\n ChronicleMetrics (df:polars.dataframe.frame.DataFrame)\n\nInitialise a chronicle metrics class\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nA polars DataFrame\n\n\nReturns\nDataFrame\n\n\n\n\n\nsource\n\n\nChronicleMetrics.describe\n\n ChronicleMetrics.describe ()\n\nReads metrics dataframe and returns a pandas dataframe with summary of service, name and description of all metrics\nThe metrics data has a single row for each collected metric.\nUse describe() to get a DataFrame of the unique metrics in the metrics data, containing the service, name and description of each metric.\n\nm = read_chronicle_metrics(\"./data\").metrics.describe()\nassert list(m) == ['service', 'name', 'description', 'value_column']\nm\n\n\nsource\n\n\nChronicleMetrics.filter\n\n ChronicleMetrics.filter (name:str, alias:str=None)\n\nExtract a single metric from a metrics dataframe\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\n\nname of metric to extract\n\n\nalias\nstr\nNone\nalias to use for new column\n\n\nReturns\nDataFrame\n\n\n\n\n\nThe name argument is used to filter the DataFrame on the name column.\n\nm = read_chronicle_metrics(\"./data\").metrics.filter(\"rsconnect_system_memory_used\")\nassert type(m) == pd.DataFrame\nassert list(m) == ['host', 'timestamp', 'rsconnect_system_memory_used']\n\nm = read_chronicle_metrics(\"./data\").metrics.filter(\"rsconnect_system_memory_used\", \"memory\")\nassert type(m) == pd.DataFrame\nassert list(m) == ['host', 'timestamp', 'memory']\n\nm\n\n\nsource\n\n\nChronicleMetrics.plot\n\n ChronicleMetrics.plot (name:str, alias:str=None)\n\nPlot a selected metric using a Plotly line plot\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\n\nname of metric to extract\n\n\nalias\nstr\nNone\nalias to use for new column\n\n\nReturns\nline\n\n\n\n\n\n\nm = read_chronicle_metrics(\"./data\")\np = m.metrics.plot(\"rsconnect_system_memory_used\", \"memory\")\nassert str(type(p)) == \"<class 'plotly.graph_objs._figure.Figure'>\"\n\n\nread_chronicle_metrics(\"./data\").metrics.plot(\"rsconnect_system_memory_used\", \"memory\")"
  },
  {
    "objectID": "core.html#analyse-logs",
    "href": "core.html#analyse-logs",
    "title": "core",
    "section": "Analyse logs",
    "text": "Analyse logs\n\nsource\n\nChronicleLogs\n\n ChronicleLogs (df:polars.dataframe.frame.DataFrame)\n\nInitialise a chronicle logs DataFrame\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nA polars data frame\n\n\nReturns\nDataFrame\n\n\n\n\n\nFilter logs on type\nYou can\n\nsource\n\n\n\nChronicleLogs.filter_type\n\n ChronicleLogs.filter_type (value:str)\n\nExtract all logs where type == value\n\n\n\n\nType\nDetails\n\n\n\n\nvalue\nstr\nValue to extract\n\n\nReturns\nDataFrame\n\n\n\n\n\nlogs = read_chronicle_logs(\"./data\").logs.filter_type(\"username\")\nassert type(logs) == pl.DataFrame\n\n# assert logs\n\n\nread_chronicle_logs(\"./data\").logs.filter_type(\"username\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "chronicle",
    "section": "",
    "text": "Experimental - Work in progress\n\n\n\nThe purpose of this experimental package is to expose functionality to make it easy to read, filter and manipulate chronicle parquet files."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "chronicle",
    "section": "Install",
    "text": "Install\nThe package is not yet available on PyPi.\n#| include: False\npip install py_chronicle\nYou can install from github:\npip install git+https://github.com/andrie/py-chronicle"
  },
  {
    "objectID": "index.html#how-chronicle-stores-data",
    "href": "index.html#how-chronicle-stores-data",
    "title": "chronicle",
    "section": "How Chronicle stores data",
    "text": "How Chronicle stores data\nChronicle collects and stores logs and metrics in a series of parquet files.\nUse read_chronicle() to read either logs or metrics, by specifying the path to the parquet set you need.\nThe file tree looks like this, with logs and metrics in separate folders inside v1.\n.\n└── v1/\n    ├── logs/\n    └── metrics/\nInside both logs and metrics the data is stored by date, separated by year, month and day.\n.\n└── v1/\n    ├── logs/\n    │   └── 2023/\n    │       ├── 02/\n    │       │   ├── 01\n    │       │   ├── 02\n    │       │   ├── 03\n    │       │   ├── 04\n    │       │   ├── 05\n    │       │   └── ...\n    │       ├── 03\n    │       ├── 04\n    │       └── ...\n    └── metrics/\n        └── 2023/\n            ├── 02/\n            │   ├── 01\n            │   ├── 02\n            │   ├── 03\n            │   ├── 04\n            │   ├── 05\n            │   └── ...\n            ├── 03\n            ├── 04\n            └── ..."
  },
  {
    "objectID": "index.html#working-with-metrics",
    "href": "index.html#working-with-metrics",
    "title": "chronicle",
    "section": "Working with metrics",
    "text": "Working with metrics\nSome examples.\n\nread_chronicle_metrics(\"./data\").head()\n\n\n\nshape: (5, 13)servicehostosattributesnamedescriptionunittypetimestampvalue_floatvalue_intvalue_uintvalue_columnstrstrstrlist[struct[2]]strstrstrstrdatetime[ms]f64i64u64str\"workbench-metr…\"rstudio-workbe…\"linux\"[{\"host\",\"rstudio-workbench-6b9658c77f-mn8hj\"}]\"rstudio_system…\"Graphite metri…\"\"\"gauge\"2023-04-03 16:02:20.5743.0074e900\"value_float\"\"workbench-metr…\"rstudio-workbe…\"linux\"[{\"host\",\"rstudio-workbench-6b9658c77f-mn8hj\"}]\"rstudio_system…\"Graphite metri…\"\"\"gauge\"2023-04-03 16:02:20.5743.2212e900\"value_float\"\"workbench-metr…\"rstudio-workbe…\"linux\"[{\"host\",\"rstudio-workbench-6b9658c77f-mn8hj\"}]\"rstudio_system…\"Graphite metri…\"\"\"gauge\"2023-04-03 16:02:20.5742.13864448e800\"value_float\"\"connect-metric…\"rstudio-connec…\"linux\"[{\"host\",\"rstudio-connect-68785f94cc-qzvrm\"}]\"rsconnect_syst…\"Graphite metri…\"\"\"gauge\"2023-04-03 16:24:29.9805.7377e900\"value_float\"\"connect-metric…\"rstudio-connec…\"linux\"[{\"host\",\"rstudio-connect-68785f94cc-qzvrm\"}]\"rsconnect_syst…\"Graphite metri…\"\"\"gauge\"2023-04-03 16:24:29.9807.04741376e800\"value_float\"\n\n\n\nread_chronicle_metrics(\"./data\").metrics.describe()\n\n\n\n\n\n  \n    \n      \n      service\n      name\n      description\n      value_column\n    \n  \n  \n    \n      0\n      connect-metrics\n      rsconnect_system_memory_available\n      Graphite metric rsconnect_system_memory_available\n      value_float\n    \n    \n      1\n      connect-metrics\n      rsconnect_system_memory_total\n      Graphite metric rsconnect_system_memory_total\n      value_float\n    \n    \n      2\n      connect-metrics\n      rsconnect_system_memory_used\n      Graphite metric rsconnect_system_memory_used\n      value_float\n    \n    \n      3\n      workbench-metrics\n      rstudio_system_memory_available\n      Graphite metric rstudio_system_memory_available\n      value_float\n    \n    \n      4\n      workbench-metrics\n      rstudio_system_memory_total\n      Graphite metric rstudio_system_memory_total\n      value_float\n    \n    \n      5\n      workbench-metrics\n      rstudio_system_memory_used\n      Graphite metric rstudio_system_memory_used\n      value_float\n    \n  \n\n\n\n\n\nread_chronicle_metrics(\"./data\").metrics.filter(\"rsconnect_system_memory_used\", \"memory\").head()\n\n\n\n\n\n  \n    \n      \n      host\n      timestamp\n      memory\n    \n  \n  \n    \n      0\n      rstudio-connect-68785f94cc-qzvrm\n      2023-04-03 16:00:29.980\n      1.170264e+09\n    \n    \n      1\n      rstudio-connect-68785f94cc-qzvrm\n      2023-04-03 16:01:29.980\n      1.187889e+09\n    \n    \n      2\n      rstudio-connect-68785f94cc-qzvrm\n      2023-04-03 16:02:29.980\n      1.188659e+09\n    \n    \n      3\n      rstudio-connect-68785f94cc-qzvrm\n      2023-04-03 16:03:29.980\n      1.252348e+09\n    \n    \n      4\n      rstudio-connect-68785f94cc-qzvrm\n      2023-04-03 16:04:29.980\n      1.259856e+09\n    \n  \n\n\n\n\n\nread_chronicle_metrics(\"./data\").metrics.plot(\"rsconnect_system_memory_used\", \"memory\")\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "index.html#working-with-logs",
    "href": "index.html#working-with-logs",
    "title": "chronicle",
    "section": "Working with logs",
    "text": "Working with logs\nSome examples.\n\nread_chronicle_logs(\"./data\").head()\n\n\n\nshape: (5, 6)servicehostosattributesbodytimestampstrstrstrlist[struct[2]]strdatetime[ms]\"workbench\"\"rstudio-workbe…\"linux\"[{\"data\",\"120\"}, {\"pid\",\"2.36E+02\"}, … {\"type\",\"session_suspend\"}]\"{\"pid\":236,\"us…2023-04-03 18:01:26.665\"workbench\"\"rstudio-workbe…\"linux\"[{\"data\",\"\"}, {\"pid\",\"2.36E+02\"}, … {\"type\",\"session_exit\"}]\"{\"pid\":236,\"us…2023-04-03 18:01:26.761\"connect\"\"rstudio-connec…\"linux\"[{\"user_role\",\"publisher\"}, {\"user_guid\",\"085ba4be-01b5-478b-877c-321368924c89\"}, … {\"type\",\"audit\"}]\"{\"action\":\"add…2023-04-03 19:30:35.698\"connect\"\"rstudio-connec…\"linux\"[{\"log.file.name\",\"audit.json\"}, {\"actor_description\",\"Auth Provider\"}, … {\"entry_id\",\"3.032E+03\"}]\"{\"action\":\"add…2023-04-03 19:30:35.698\"connect\"\"rstudio-connec…\"linux\"[{\"action\",\"add_group_member\"}, {\"actor_id\",\"0E+00\"}, … {\"log.file.name\",\"audit.json\"}]\"{\"action\":\"add…2023-04-03 19:30:35.698\n\n\n\nread_chronicle_logs(\"./data\").logs.filter_type(\"username\").head()\n\n\n\nshape: (5, 6)servicehosttimestamp.username.typebodystrstrdatetime[ms]strstrstr\"workbench\"\"rstudio-workbe…2023-04-03 18:01:26.761\"james\"\"session_exit\"\"{\"pid\":236,\"us…\"workbench\"\"rstudio-workbe…2023-04-07 03:46:57.960\"james\"\"auth_login\"\"{\"pid\":1059,\"u…\"workbench\"\"rstudio-workbe…2023-04-07 03:51:15.161\"james\"\"session_start\"\"{\"pid\":236,\"us…\"workbench\"\"rstudio-workbe…2023-04-07 04:19:18.561\"james\"\"session_exit\"\"{\"pid\":236,\"us…\"workbench\"\"rstudio-workbe…2023-04-07 04:19:19.764\"james\"\"session_start\"\"{\"pid\":883,\"us…"
  },
  {
    "objectID": "io.html",
    "href": "io.html",
    "title": "io",
    "section": "",
    "text": "source\n\nwrite_parquet\n\n write_parquet (x:polars.dataframe.frame.DataFrame, filename:str)\n\nWrite chronicle data to parquet file\n\n\n\n\nType\nDetails\n\n\n\n\nx\nDataFrame\npolars DataFrame\n\n\nfilename\nstr\nFull file file name\n\n\nReturns\nNone\n\n\n\n\n\nm = read_chronicle_metrics(\"./data\")\n\n# create a temporary file\ntf = tempfile.NamedTemporaryFile(suffix = \".parquet\")\nassert os.path.getsize(tf.name) == 0\nz = write_parquet(m, tf)\n\nassert os.path.getsize(tf.name) > 0\nassert z is None\n\n\nsource\n\n\nget_s3_bucket_dates\n\n get_s3_bucket_dates (bucket:str, type='logs', version='v1')\n\nGet a list of dates for which there are chronicle logs or metrics in an S3 bucket\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbucket\nstr\n\nS3 bucket name, without the “s3://” prefix\n\n\ntype\nstr\nlogs\n“logs” or “metrics”\n\n\nversion\nstr\nv1\n“v1” or “v2”\n\n\nReturns\nlist\n\n\n\n\n\n\nbucket = \"colorado-posit-chronicle\"\nget_s3_bucket_dates(bucket, \"metrics\")"
  }
]