# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/io.ipynb.

# %% auto 0
__all__ = ['write_parquet', 'get_s3_bucket_dates']

# %% ../nbs/io.ipynb 3
import polars as pl
import pyarrow.parquet as pq
from pyarrow import fs
# import pyarrow.dataset as ds
# from s3fs import S3FileSystem
import tempfile
import os
import re
from .core import read_chronicle_metrics

# %% ../nbs/io.ipynb 4
def write_parquet(
        x: pl.DataFrame, # polars DataFrame
        filename:str # Full file file name
    ) -> None:
    "Write chronicle data to parquet file"
    return pq.write_table(x.to_arrow(), filename)


# %% ../nbs/io.ipynb 6
def get_s3_bucket_dates(
        bucket:str, # S3 bucket name, without the "s3://" prefix 
        type="logs", # "logs" or "metrics"
        version="v1" # "v1" or "v2"
    ) -> list:
    "Get a list of dates for which there are chronicle logs or metrics in an S3 bucket"
    s3 = fs.S3FileSystem()
    p = s3.get_file_info(
        fs.FileSelector(
            f'{bucket}/{version}/{type}', 
            recursive=True)
        )
    # list all paths where type == file
    ps = [x.path for x in p if x.type == 2]
    # extract dates using a regular expression
    dates = [re.findall(r'\d{4}/\d{2}/\d{2}', x)[0] for x in ps]
    # convert to a set to get unique values
    dates = list(set(dates))
    dates.sort()
    return dates
