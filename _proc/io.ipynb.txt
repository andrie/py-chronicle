{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# io\n",
    "\n",
    "> File operations on chronicle parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import polars as pl\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "from s3fs import S3FileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def write_parquet(\n",
    "        x: pl.DataFrame, # polars DataFrame\n",
    "        filename:str # Full file file name\n",
    "    ) -> None:\n",
    "    \"Write chronicle data to parquet file\"\n",
    "    return pq.write_table(x.to_arrow(), filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chronicle.core import read_chronicle_metrics\n",
    "m = read_chronicle_metrics(\"./data\")\n",
    "\n",
    "# create a temporary file\n",
    "import tempfile\n",
    "import os\n",
    "tf = tempfile.NamedTemporaryFile(suffix = \".parquet\")\n",
    "assert os.path.getsize(tf.name) == 0\n",
    "z = write_parquet(m, tf)\n",
    "\n",
    "assert os.path.getsize(tf.name) > 0\n",
    "assert z is None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
